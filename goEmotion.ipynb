{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d3055e",
   "metadata": {},
   "source": [
    "# Team 19 - COMP 472 (Artificial Intelligence) Mini Project 1: Emotion and Sentiment Classification of Reddit Posts\n",
    "by\n",
    "Vithushen Sivasubramaniam (40112363), Vejay Thanamjeyasingam (40112236), and David Xie (40065595)\n",
    "\n",
    "October 22, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f0f080",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation & Analysis (5pts)\n",
    "\n",
    "### 1.1. □ (0pts) Download the version of the GoEmotion dataset provided on Moodle.\n",
    "The original GoEmotion dataset, created by [Demszky et al., 2020], is a dataset of 58k humanannotated\n",
    "Reddit comments labeled with 27+1 emotion categories (eg. admiration, amusement, anger,\n",
    "caring, . . . ) and neutral. These emotions are themselves organized into 4 sentiments: positive (admiration,\n",
    "amusement, . . . ), negative (anger, annoyance, . . . ), ambiguous (confusion, curiosity) and\n",
    "neutral (neutral )). This allows us to use the dataset for both:\n",
    "* emotion classification (into 28 classes), and\n",
    "* sentiment classification (into 4 classes).\n",
    "\n",
    "For more information on the original dataset, you can read this blog and this paper.\n",
    "The dataset we will use for this assignment is a modified version of the original GoEmotion, where only\n",
    "posts annotated with a single emotion (and a single sentiment) are kept, and the data is formatted in\n",
    "json. The json file contains triplets made of the post, its emotion and its sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a7f364",
   "metadata": {},
   "source": [
    "### 1.2. □ (0pts) Load the dataset. \n",
    "You can use gzip.open and json.load to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e776c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# opens file using GZIP and json.load\n",
    "with gzip.open('goemotions.json.gz', 'rb') as f:\n",
    "    file_content = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3323ce65",
   "metadata": {},
   "source": [
    "### 1.3. □ (5pts) Extract the posts and the 2 sets of labels (emotion and sentiment), then plot the distribution of the posts in each category and save the graphic (a histogram or pie chart) in pdf. \n",
    "\n",
    "Do this for both the emotion and the sentiment categories. You can use matplotlib.pyplot and savefig to do this. This pre-analysis of the dataset will allow you to determine if the classes are balanced, and which metric is more appropriate to use to evaluate the performance of your classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check contents of file\n",
    "file_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a038482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store emotions and sentiments in list\n",
    "emotionList = []\n",
    "sentimentList = []\n",
    "\n",
    "for post in file_content:\n",
    "    emotionList.append(post[1])\n",
    "    sentimentList.append(post[2])\n",
    "    \n",
    "# Generate graphs using sentiment and emotion Lists\n",
    "plt.figure(0)\n",
    "plt.title('Distribution of Sentiments', pad=100, fontdict = {'fontsize' : 20})\n",
    "plt.pie(Counter(sentimentList).values(), labels=Counter(sentimentList).keys(), radius=2, autopct=\"%0.1f%%\")\n",
    "plt.savefig(\"sentimentGraph.pdf\", bbox_inches='tight')\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Distribution of Emotions', pad=450, fontdict = {'fontsize' : 50})\n",
    "plt.pie(Counter(emotionList).values(), labels=Counter(emotionList).keys(), radius=5, autopct=\"%0.1f%%\")\n",
    "plt.savefig(\"emotionGraph.pdf\", bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c13cf5",
   "metadata": {},
   "source": [
    "### 2.1. □ (5pts) Process the dataset using feature extraction.text.CountVectorizer to extract tokens/words and their frequencies. \n",
    "Display the number of tokens (the size of the vocabulary) in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa3d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display number of tokens and their frequencies\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vocabularyList = []\n",
    "\n",
    "cv=CountVectorizer()\n",
    "\n",
    "for post in file_content:\n",
    "    vocabularyList.append(post[0])\n",
    "\n",
    "Z=cv.fit(vocabularyList)\n",
    "print(\"Number of tokens: \", len(Z.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873d8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Z.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535085b7",
   "metadata": {},
   "source": [
    "### 2.2. □ (2pts) Split the dataset into 80% for training and 20% for testing. \n",
    "For this, you can use train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3161fa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset (80% training and 20% testing)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=emotionList #might be the Reddit posts\n",
    "y=sentimentList #may need have 2: one for sentiment, one for emotion\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.20) #may need to split twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8037bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
